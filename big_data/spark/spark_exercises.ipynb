{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Apache Spark Exercises\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exercise 0: Setup SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Spark Exercises\").getOrCreate()\n",
        "print(\"SparkSession created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1 — Create a SparkSession & DataFrame\n",
        "**Goal:** Learn how to start Spark and create a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = [\n",
        "    (1, \"Alice\", 25),\n",
        "    (2, \"Bob\", 30)\n",
        "]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\", \"age\"])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 2 — Select & Rename Columns\n",
        "**Goal:** Select specific columns and rename them using `alias`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df = spark.read.csv(\"data/people.csv\", header=True, inferSchema=True)\n",
        "people_df.select(\"name\", \"age\").show()\n",
        "people_df.select(people_df.name.alias(\"person_name\"), \"age\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 3 — Filter Rows\n",
        "**Goal:** Filter rows using conditions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df.filter(people_df.age > 30).show()\n",
        "people_df.filter(people_df.city == \"London\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 4 — Sort and Limit\n",
        "**Goal:** Sort DataFrame rows and limit results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df.orderBy(people_df.age.desc()).show()\n",
        "people_df.orderBy(people_df.age).limit(2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 5 — Group By\n",
        "**Goal:** Group data and count per group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df.groupBy(\"city\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 6 — Aggregations\n",
        "**Goal:** Perform aggregations like `avg` and `max`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import avg, max\n",
        "people_df.groupBy(\"city\").agg(\n",
        "    avg(\"age\").alias(\"avg_age\"),\n",
        "    max(\"age\").alias(\"max_age\")\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 7 — Read & Write CSV\n",
        "**Goal:** Read data from CSV and write Spark output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df.write.mode(\"overwrite\").csv(\"output/people_output\", header=True)\n",
        "print(\"Data written to output/people_output/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 8 — Spark SQL\n",
        "**Goal:** Use SQL queries on DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "people_df.createOrReplaceTempView(\"people\")\n",
        "spark.sql(\"\"\"\n",
        "SELECT city, AVG(age) AS avg_age\n",
        "FROM people\n",
        "GROUP BY city\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 9 — Join DataFrames\n",
        "**Goal:** Join two DataFrames (people and sales)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sales_df = spark.read.csv(\"data/sales.csv\", header=True, inferSchema=True)\n",
        "joined_df = people_df.join(sales_df, people_df.id == sales_df.person_id, \"inner\")\n",
        "joined_df.select(\"name\", \"amount\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 10 — User Defined Function (UDF)\n",
        "**Goal:** Apply custom Python logic to a DataFrame column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def age_group(age):\n",
        "    if age < 30:\n",
        "        return \"Young\"\n",
        "    elif age < 40:\n",
        "        return \"Adult\"\n",
        "    else:\n",
        "        return \"Senior\"\n",
        "\n",
        "age_group_udf = udf(age_group, StringType())\n",
        "people_df.withColumn(\"age_group\", age_group_udf(people_df.age)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "Stop Spark session when done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "spark.stop()\n",
        "print(\"Spark session stopped\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
